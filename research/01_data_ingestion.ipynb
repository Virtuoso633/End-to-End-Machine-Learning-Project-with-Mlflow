{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sanket/Documents/ML Project/Full-Stack Machine Learning Deployment with MLOps and AWS EC2/research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sanket/Documents/ML Project/Full-Stack Machine Learning Deployment with MLOps and AWS EC2/research\n"
     ]
    }
   ],
   "source": [
    "# Print current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sanket/Documents/ML Project/Full-Stack Machine Learning Deployment with MLOps and AWS EC2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MlOpsProject.constants import *\n",
    "from MlOpsProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "        \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            source_URL = config.source_URL,\n",
    "            local_data_file = config.local_data_file,\n",
    "            unzip_dir = config.unzip_dir\n",
    "        )\n",
    "        \n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from MlOpsProject import logger\n",
    "from MlOpsProject.utils.common import get_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig): # The constructor (__init__) initializes the class with a configuration object config of type DataIngestionConfig.\n",
    "        self.config = config # self.config: This stores the configuration object, which is expected to contain the settings needed for data ingestion, such as the source URL and the local file path.\n",
    "    \n",
    "    def download_file(self):\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            filename, headers = request.urlretrieve( \n",
    "                url = self.config.source_URL,\n",
    "                filename = self.config.local_data_file\n",
    "            )\n",
    "            logger.info(f\"{filename} download! with following info: \\n{headers}\")\n",
    "            # If the file does not exist:\n",
    "            # It uses 'request.urlretrieve' to download the file from the URL specified by 'self.config.source_URL' and saves it to the local path specified by 'self.config.local_data_file'.\n",
    "            # 'filename' and 'headers' capture the file path and the HTTP headers received during the download.\n",
    "            # A log message is generated using 'logger.info', indicating the download is complete, along with information from the headers.\n",
    "        else:\n",
    "            logger.info(f\"File already exists of size : {get_size(Path(self.config.local_data_file))}\")\n",
    "            #It logs a message indicating that the file already exists and displays its size using the get_size function, which takes the local file path as a parameter.\n",
    "            \n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file path : str\n",
    "        Extracts the zip file into the data directory\n",
    "        Funtion returns None\n",
    "        \"\"\"\n",
    "        \n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path,exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file,'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-04 16:14:08,378: INFO: common: YAML file: config/config.yaml loaded successfully.]\n",
      "[2024-10-04 16:14:08,380: INFO: common: YAML file: params.yaml loaded successfully.]\n",
      "[2024-10-04 16:14:08,383: INFO: common: YAML file: schema.yaml loaded successfully.]\n",
      "[2024-10-04 16:14:08,385: INFO: common: created directory at: artifacts]\n",
      "[2024-10-04 16:14:08,386: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2024-10-04 16:14:08,387: INFO: 1418873313: File already exists of size : ~ 25 KB]\n"
     ]
    }
   ],
   "source": [
    "try: # This block attempts to execute the data ingestion workflow, and if any errors occur, they are caught by the except block.\n",
    "    config = ConfigurationManager() # An instance of the 'ConfigurationManager' class is created. This class is likely responsible for managing and providing configurations required for the application.\n",
    "    data_ingestion_config = config.get_data_ingestion_config() # An instance of the ConfigurationManager class is created. This class is likely responsible for managing and providing configurations required for the application.\n",
    "    data_ingestion = DataIngestion(config= data_ingestion_config) # The 'get_data_ingestion_config' method of the 'ConfigurationManager' object is called to retrieve the specific configuration settings for data ingestion. This configuration object (data_ingestion_config) contains information like URLs, file paths, and other parameters required for the data ingestion process\n",
    "    data_ingestion.download_file()# The download_file method of the DataIngestion instance is called to handle the file download operation. It checks if the file already exists and, if not, downloads it from the specified URL.\n",
    "    data_ingestion.extract_zip_file() # This line calls the extract_zip_file method on the DataIngestion instance. It handles the extraction of downloaded zip files. This would typically involve unzipping the downloaded file and saving its contents to a specified location\n",
    "except Exception as e:\n",
    "    raise e # When an exception is caught, it is re-raised using raise e, allowing it to propagate up the call stack without modifying the original exception. This preserves the error context and stack trace, making it easier to diagnose the problem.\n",
    "\n",
    "## Yaml file is empty error initially.\n",
    "# The error indicates that the YAML file being read is empty, meaning it does not contain any data. \n",
    "# Let's add some dummy values for time being in schema.yaml and params.yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myMlProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
